<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse</title>
  <meta name="description" content="Welcome to the wonderful world of data science and R !" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Welcome to the wonderful world of data science and R !" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  
  <meta name="twitter:description" content="Welcome to the wonderful world of data science and R !" />
  

<meta name="author" content="Vivien Roussez (A1 Telekom Austria Group)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multivar.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data exploration and statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#topics-of-the-week"><i class="fa fa-check"></i><b>2.1</b> Topics of the week</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#the-data-science-workflow"><i class="fa fa-check"></i><b>2.2</b> The data science workflow</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#about-the-interactions-with-other-colleagues"><i class="fa fa-check"></i><b>2.3</b> About the interactions with other colleagues</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#resources"><i class="fa fa-check"></i><b>2.4</b> Resources</a></li>
<li class="chapter" data-level="2.5" data-path="intro.html"><a href="intro.html#data-of-the-week"><i class="fa fa-check"></i><b>2.5</b> Data of the week</a></li>
<li class="chapter" data-level="2.6" data-path="intro.html"><a href="intro.html#your-mission"><i class="fa fa-check"></i><b>2.6</b> Your mission</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro-r.html"><a href="intro-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to R</a><ul>
<li class="chapter" data-level="3.1" data-path="intro-r.html"><a href="intro-r.html#what-is-r"><i class="fa fa-check"></i><b>3.1</b> What is R</a><ul>
<li class="chapter" data-level="3.1.1" data-path="intro-r.html"><a href="intro-r.html#description"><i class="fa fa-check"></i><b>3.1.1</b> Description</a></li>
<li class="chapter" data-level="3.1.2" data-path="intro-r.html"><a href="intro-r.html#objective-comparison-with-pyhton"><i class="fa fa-check"></i><b>3.1.2</b> (Objective) comparison with Pyhton</a></li>
<li class="chapter" data-level="3.1.3" data-path="intro-r.html"><a href="intro-r.html#what-can-i-do-with-r"><i class="fa fa-check"></i><b>3.1.3</b> What can I do with R</a></li>
<li class="chapter" data-level="3.1.4" data-path="intro-r.html"><a href="intro-r.html#quick-presentation-of-the-ecosystem"><i class="fa fa-check"></i><b>3.1.4</b> Quick presentation of the ecosystem</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="intro-r.html"><a href="intro-r.html#basic-commands-to-know"><i class="fa fa-check"></i><b>3.2</b> Basic commands to know</a></li>
<li class="chapter" data-level="3.3" data-path="intro-r.html"><a href="intro-r.html#data-structures-in-r"><i class="fa fa-check"></i><b>3.3</b> Data structures in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="intro-r.html"><a href="intro-r.html#basic-data-structures"><i class="fa fa-check"></i><b>3.3.1</b> Basic data structures</a></li>
<li class="chapter" data-level="3.3.2" data-path="intro-r.html"><a href="intro-r.html#explore-a-new-data-structure-or-object"><i class="fa fa-check"></i><b>3.3.2</b> Explore a new data structure (or object)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="manip.html"><a href="manip.html"><i class="fa fa-check"></i><b>4</b> Data manipulation</a><ul>
<li class="chapter" data-level="4.1" data-path="manip.html"><a href="manip.html#import"><i class="fa fa-check"></i><b>4.1</b> Import</a><ul>
<li class="chapter" data-level="4.1.1" data-path="manip.html"><a href="manip.html#text-files"><i class="fa fa-check"></i><b>4.1.1</b> Text files</a></li>
<li class="chapter" data-level="4.1.2" data-path="manip.html"><a href="manip.html#excel-files"><i class="fa fa-check"></i><b>4.1.2</b> Excel files</a></li>
<li class="chapter" data-level="4.1.3" data-path="manip.html"><a href="manip.html#more-formats"><i class="fa fa-check"></i><b>4.1.3</b> More formats</a></li>
<li class="chapter" data-level="4.1.4" data-path="manip.html"><a href="manip.html#read-from-databases-big-data"><i class="fa fa-check"></i><b>4.1.4</b> Read from databases / big data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="manip.html"><a href="manip.html#the-grammar-of-data-manipulation"><i class="fa fa-check"></i><b>4.2</b> The grammar of data manipulation</a><ul>
<li class="chapter" data-level="4.2.1" data-path="manip.html"><a href="manip.html#the-pipe"><i class="fa fa-check"></i><b>4.2.1</b> The pipe</a></li>
<li class="chapter" data-level="4.2.2" data-path="manip.html"><a href="manip.html#the-verbs-of-manipulation"><i class="fa fa-check"></i><b>4.2.2</b> The verbs of manipulation</a></li>
<li class="chapter" data-level="4.2.3" data-path="manip.html"><a href="manip.html#filter-conditions"><i class="fa fa-check"></i><b>4.2.3</b> Filter : conditions</a></li>
<li class="chapter" data-level="4.2.4" data-path="manip.html"><a href="manip.html#mutate"><i class="fa fa-check"></i><b>4.2.4</b> Mutate</a></li>
<li class="chapter" data-level="4.2.5" data-path="manip.html"><a href="manip.html#summarize"><i class="fa fa-check"></i><b>4.2.5</b> Summarize</a></li>
<li class="chapter" data-level="4.2.6" data-path="manip.html"><a href="manip.html#manipulate-several-data-in-the-same-time"><i class="fa fa-check"></i><b>4.2.6</b> Manipulate several data in the same time</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="manip.html"><a href="manip.html#lets-import-and-wrangle-some-data"><i class="fa fa-check"></i><b>4.3</b> Let’s import and wrangle some data !</a><ul>
<li class="chapter" data-level="4.3.1" data-path="manip.html"><a href="manip.html#the-data"><i class="fa fa-check"></i><b>4.3.1</b> The data</a></li>
<li class="chapter" data-level="4.3.2" data-path="manip.html"><a href="manip.html#one-tool-you-will-need-lapply"><i class="fa fa-check"></i><b>4.3.2</b> One tool you will need : <code>lapply()</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="manip.html"><a href="manip.html#tidy-your-data"><i class="fa fa-check"></i><b>4.4</b> Tidy your data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>5</b> Statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="stats.html"><a href="stats.html#definitions"><i class="fa fa-check"></i><b>5.1</b> Definitions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="stats.html"><a href="stats.html#terminology"><i class="fa fa-check"></i><b>5.1.1</b> Terminology</a></li>
<li class="chapter" data-level="5.1.2" data-path="stats.html"><a href="stats.html#types-of-variables"><i class="fa fa-check"></i><b>5.1.2</b> Types of variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stats.html"><a href="stats.html#univariate-statistics"><i class="fa fa-check"></i><b>5.2</b> Univariate statistics</a><ul>
<li class="chapter" data-level="5.2.1" data-path="stats.html"><a href="stats.html#numerical-variables"><i class="fa fa-check"></i><b>5.2.1</b> Numerical variables</a></li>
<li class="chapter" data-level="5.2.2" data-path="stats.html"><a href="stats.html#categorical-variables"><i class="fa fa-check"></i><b>5.2.2</b> Categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="stats.html"><a href="stats.html#bivariate-statistics"><i class="fa fa-check"></i><b>5.3</b> Bivariate statistics</a><ul>
<li class="chapter" data-level="5.3.1" data-path="stats.html"><a href="stats.html#continuous-variables"><i class="fa fa-check"></i><b>5.3.1</b> 2 continuous variables</a></li>
<li class="chapter" data-level="5.3.2" data-path="stats.html"><a href="stats.html#categorical-variables-1"><i class="fa fa-check"></i><b>5.3.2</b> 2 categorical variables</a></li>
<li class="chapter" data-level="5.3.3" data-path="stats.html"><a href="stats.html#continuous-1-categorical-variable"><i class="fa fa-check"></i><b>5.3.3</b> 1 continuous, 1 categorical variable</a></li>
<li class="chapter" data-level="5.3.4" data-path="stats.html"><a href="stats.html#exercises-1"><i class="fa fa-check"></i><b>5.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="stats.html"><a href="stats.html#stat_inf"><i class="fa fa-check"></i><b>5.4</b> Statistical inference</a><ul>
<li class="chapter" data-level="5.4.1" data-path="stats.html"><a href="stats.html#the-statistical-model"><i class="fa fa-check"></i><b>5.4.1</b> The statistical model</a></li>
<li class="chapter" data-level="5.4.2" data-path="stats.html"><a href="stats.html#two-fundamental-theorems"><i class="fa fa-check"></i><b>5.4.2</b> Two fundamental theorems</a></li>
<li class="chapter" data-level="5.4.3" data-path="stats.html"><a href="stats.html#statistical-tests"><i class="fa fa-check"></i><b>5.4.3</b> Statistical tests</a></li>
<li class="chapter" data-level="5.4.4" data-path="stats.html"><a href="stats.html#other-estimators-maximum-of-likelihood"><i class="fa fa-check"></i><b>5.4.4</b> Other estimators : maximum of likelihood</a></li>
<li class="chapter" data-level="5.4.5" data-path="stats.html"><a href="stats.html#exercises-interprete-a-test-you-dont-know"><i class="fa fa-check"></i><b>5.4.5</b> Exercises : interprete a test you don’t know</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivar.html"><a href="multivar.html"><i class="fa fa-check"></i><b>6</b> Multivariate analysis and dimension reduction</a><ul>
<li class="chapter" data-level="6.1" data-path="multivar.html"><a href="multivar.html#multivariate-analysis"><i class="fa fa-check"></i><b>6.1</b> Multivariate analysis</a><ul>
<li class="chapter" data-level="6.1.1" data-path="multivar.html"><a href="multivar.html#advanced-visualization"><i class="fa fa-check"></i><b>6.1.1</b> Advanced visualization</a></li>
<li class="chapter" data-level="6.1.2" data-path="multivar.html"><a href="multivar.html#easily-explore-an-entire-dataset"><i class="fa fa-check"></i><b>6.1.2</b> Easily explore an entire dataset</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multivar.html"><a href="multivar.html#multivariate-analysis-and-dimension-reduction"><i class="fa fa-check"></i><b>6.2</b> Multivariate analysis and dimension reduction</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multivar.html"><a href="multivar.html#imputation"><i class="fa fa-check"></i><b>6.2.1</b> Imputation</a></li>
<li class="chapter" data-level="6.2.2" data-path="multivar.html"><a href="multivar.html#normalization"><i class="fa fa-check"></i><b>6.2.2</b> Normalization</a></li>
<li class="chapter" data-level="6.2.3" data-path="multivar.html"><a href="multivar.html#pca"><i class="fa fa-check"></i><b>6.2.3</b> PCA</a></li>
<li class="chapter" data-level="6.2.4" data-path="stats.html"><a href="stats.html#exercises"><i class="fa fa-check"></i><b>6.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multivar.html"><a href="multivar.html#dimension-reduction"><i class="fa fa-check"></i><b>6.3</b> Dimension reduction</a><ul>
<li class="chapter" data-level="6.3.1" data-path="multivar.html"><a href="multivar.html#use-the-results-of-the-pca"><i class="fa fa-check"></i><b>6.3.1</b> Use the results of the PCA</a></li>
<li class="chapter" data-level="6.3.2" data-path="multivar.html"><a href="multivar.html#other-inertia-based-methods"><i class="fa fa-check"></i><b>6.3.2</b> Other inertia-based methods</a></li>
<li class="chapter" data-level="6.3.3" data-path="multivar.html"><a href="multivar.html#t-sne"><i class="fa fa-check"></i><b>6.3.3</b> t-SNE</a></li>
<li class="chapter" data-level="6.3.4" data-path="multivar.html"><a href="multivar.html#a-word-about-clustering"><i class="fa fa-check"></i><b>6.3.4</b> A word about clustering</a></li>
<li class="chapter" data-level="6.3.5" data-path="intro-r.html"><a href="intro-r.html#exercise"><i class="fa fa-check"></i><b>6.3.5</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="multivar.html"><a href="multivar.html#visualization-bonus-dashboards-and-reports"><i class="fa fa-check"></i><b>6.4</b> Visualization bonus : dashboards and reports</a><ul>
<li class="chapter" data-level="6.4.1" data-path="multivar.html"><a href="multivar.html#shiny-and-rmarkdown"><i class="fa fa-check"></i><b>6.4.1</b> Shiny and rmarkdown</a></li>
<li class="chapter" data-level="6.4.2" data-path="multivar.html"><a href="multivar.html#web-based-graphics-with-plotly"><i class="fa fa-check"></i><b>6.4.2</b> Web-based graphics with <code>plotly</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="multivar.html"><a href="multivar.html#other-packages-widgets"><i class="fa fa-check"></i><b>6.4.3</b> Other packages &amp; widgets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>7</b> Linear and logistic regression</a><ul>
<li class="chapter" data-level="7.1" data-path="reg.html"><a href="reg.html#linear-regression"><i class="fa fa-check"></i><b>7.1</b> Linear regression</a><ul>
<li class="chapter" data-level="7.1.1" data-path="reg.html"><a href="reg.html#general-presentation"><i class="fa fa-check"></i><b>7.1.1</b> General presentation</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg.html"><a href="reg.html#coefficients-interpretation-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Coefficients interpretation and inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg.html"><a href="reg.html#the-frischwaugh-theorem-and-the-omitted-variable-bias"><i class="fa fa-check"></i><b>7.1.3</b> The Frisch–Waugh Theorem and the omitted variable bias</a></li>
<li class="chapter" data-level="7.1.4" data-path="reg.html"><a href="reg.html#feature-engineering-and-functional-specification"><i class="fa fa-check"></i><b>7.1.4</b> Feature engineering and functional specification</a></li>
<li class="chapter" data-level="7.1.5" data-path="reg.html"><a href="reg.html#variable-selection"><i class="fa fa-check"></i><b>7.1.5</b> Variable selection</a></li>
<li class="chapter" data-level="7.1.6" data-path="stats.html"><a href="stats.html#exercises"><i class="fa fa-check"></i><b>7.1.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="reg.html"><a href="reg.html#logitic-regression"><i class="fa fa-check"></i><b>7.2</b> Logitic regression</a><ul>
<li class="chapter" data-level="7.2.1" data-path="reg.html"><a href="reg.html#mathematical-formulation"><i class="fa fa-check"></i><b>7.2.1</b> Mathematical formulation</a></li>
<li class="chapter" data-level="7.2.2" data-path="reg.html"><a href="reg.html#implementation-in-r-and-interpretation"><i class="fa fa-check"></i><b>7.2.2</b> Implementation in R and interpretation</a></li>
<li class="chapter" data-level="7.2.3" data-path="reg.html"><a href="reg.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.2.3</b> Goodness of fit</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data exploration and statistics with R and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Linear and logistic regression</h1>
<p>Regression is the first machine learning algorithm. It allows you to model a <em>target variable</em> <span class="math inline">\(y\)</span> depending on a set of <em>explanatory variables</em> or <em>features</em> <span class="math inline">\(X\)</span> such that <span class="math inline">\(y=f(X) + \epsilon\)</span> where <span class="math inline">\(f\)</span> is a linear function (for linear regression).</p>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">7.1</span> Linear regression</h2>
<p>We will jump directly to the <em>multiple regression model</em>, which is the generalization of the simple linear model, which you can check <a href="https://www.econometrics-with-r.org/4-lrwor.html">here</a></p>
<div id="general-presentation" class="section level3">
<h3><span class="header-section-number">7.1.1</span> General presentation</h3>
<p>The basic equation of the linear regression is
<span class="math display">\[ y_i = x_i \cdot b + \epsilon_i \Leftrightarrow y_i = \sum_{j=1}^p x_{ij} b_j + \epsilon_i\]</span></p>
<p>Where :</p>
<ul>
<li><span class="math inline">\(x_i\)</span> is a row-vector of size p (number of explanatory variables), containng the values of each feature of observation i. It is the row i of the matrix <span class="math inline">\(X = (x_{ij})\)</span></li>
<li>b is a column-vector of coefficients, one per explanatory variable</li>
<li><span class="math inline">\(\epsilon_i\)</span> is the error term for observation i</li>
</ul>
<p>This regression is said to be linear because it is <em>linear in the parameters</em>, you can however transform the original variables at will with non-linear functions (see feature engineering).</p>
<p>The biggest assumptions of this model are :</p>
<ul>
<li>Observations are iid</li>
<li>There is no perfect multi-collinearity among features</li>
<li><span class="math inline">\(\epsilon_i\)</span> has a zero conditional mean <span class="math inline">\(\mathbb{E}(\epsilon | X)=0\)</span></li>
</ul>
<p>This last condition helps us to derive an estimator for b (which can be derived in several ways) which is called the OLS estimator (Ordinary Least Squares), which is the solution of the optimization program :</p>
<p><span class="math display">\[\hat{b}=argmin_b \sum_{i=1}^n \epsilon_i^2 = argmin_b \sum_{i=1}^n (x_i-x_i \cdot b)^2\]</span></p>
<p>The solution is <span class="math inline">\(\hat{b} = (X&#39;X)^{-1}X&#39;y\)</span> where <span class="math inline">\(X&#39;=t(X)\)</span>. <span class="math inline">\((X&#39;X)^{-1}X\)</span> is the projection matrix over the hyperplane defined by the features.</p>
<p><img src="img/ols-regression-geometry.png" />
### Implementation and diagnostics</p>
<p>To implement a linear regression with R, we use the lm function :</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="reg.html#cb241-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower, <span class="dt">data=</span>dat_bike)</span>
<span id="cb241-2"><a href="reg.html#cb241-2"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower, data = dat_bike)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -29.460  -3.588  -1.053   3.133  22.718 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    109.32567    6.69319  16.334  &lt; 2e-16 ***
## avgPower         0.25349    0.02257  11.231  &lt; 2e-16 ***
## avgBikeCadence  -1.41346    0.07388 -19.131  &lt; 2e-16 ***
## distance         0.09537    0.01205   7.917 1.14e-14 ***
## avgHr           -0.04565    0.03239  -1.410    0.159    
## max20MinPower   -0.06764    0.01523  -4.441 1.06e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.566 on 616 degrees of freedom
##   (1870 observations deleted due to missingness)
## Multiple R-squared:  0.8309,	Adjusted R-squared:  0.8296 
## F-statistic: 605.6 on 5 and 616 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The goodness of fit is measured through 2 main statistics :</p>
<ul>
<li>Adjusted R-squared, <span class="math inline">\(1- \dfrac{n-1}{n-k-1} \dfrac{SSR}{TSS} \in [0,1]\)</span>, which takes the number of regressors into account. The closer to 1, the better the fit</li>
<li>RMSE (root mean squared error), or residual standard error which has to be compared to the average value of <span class="math inline">\(y\)</span>. the smaller the value, the better the fit.</li>
</ul>
</div>
<div id="coefficients-interpretation-and-inference" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Coefficients interpretation and inference</h3>
<p>Back to original equation, we can understand how much each feature influences in average the output.</p>
<p><span class="math display">\[ \dfrac{\partial y}{\partial x_1} = b_1\]</span>
Meaning that the increase of <span class="math inline">\(x_1\)</span> by one unit causes the output to increase in average by <span class="math inline">\(b_1\)</span> (which can of course be negative). In our example, one additional watt will result in an increase of the average speed by 0.25 km/h</p>
<p>The fundamental hypothesis being fulfilled and the sample being large enough, the distribution of the OLS estimate <span class="math inline">\((b_1,...,b_p)\)</span> are jointly normally distributed, meaning that each <span class="math inline">\(\hat{b_j} \hookrightarrow \mathcal{N}(b_j,\sigma_{b_j}^2)\)</span>
We can therefore perform statistical tests following the previous methodology (see @ref(stat_inf).</p>
<p>The most common test is the Student test which tests the null hypothesis <span class="math inline">\(b_i=0\)</span>. This allows to check whether a regressor has a significant effect on the target variable or not.</p>
<p>But you have to check your residuals !</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="reg.html#cb243-1"></a><span class="kw">residuals</span>(reg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb243-2"><a href="reg.html#cb243-2"></a><span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">res=</span>.) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb243-3"><a href="reg.html#cb243-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(res)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_density</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="DataExploration_files/figure-html/unnamed-chunk-96-1.png" width="672" />
Those are pretty long tailed, which might reflect some outliers or a wrong functional specification !</p>
</div>
<div id="the-frischwaugh-theorem-and-the-omitted-variable-bias" class="section level3">
<h3><span class="header-section-number">7.1.3</span> The Frisch–Waugh Theorem and the omitted variable bias</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem">Frisch-Waugh theorem</a> tells us that adding a variable as regressor ensures that our estimates controls for the effect of this variable. In other words, you can interpret the coefficients’ values <em>ceteris paribus</em> (other things equal).</p>
<p>This also means that if you omit a variable, the coefficient of the other variables are likely to be biased, because you did not take an important variable into account. Back to our example, we can add the elevationGain variable and check what happens :</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="reg.html#cb244-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower <span class="op">+</span><span class="st"> </span>elevationGain, <span class="dt">data=</span>dat_bike)</span>
<span id="cb244-2"><a href="reg.html#cb244-2"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.6200  -3.8680  -0.5302   2.6892  19.5814 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     1.265e+02  6.630e+00  19.076  &lt; 2e-16 ***
## avgPower        1.374e-01  2.354e-02   5.837 1.02e-08 ***
## avgBikeCadence -1.521e+00  7.511e-02 -20.253  &lt; 2e-16 ***
## distance        1.987e-01  1.431e-02  13.884  &lt; 2e-16 ***
## avgHr           7.929e-03  3.149e-02   0.252    0.801    
## max20MinPower  -7.367e-03  1.547e-02  -0.476    0.634    
## elevationGain  -1.281e-02  9.543e-04 -13.424  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.938 on 450 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.8086,	Adjusted R-squared:  0.8061 
## F-statistic: 316.9 on 6 and 450 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>See how the coefficients changed. This is understandable because when climbing mountains :</p>
<ul>
<li>More power will not increase the speed, just maintain it (… or not)</li>
<li>The cadence is harder to maintain unless you have unlimited gears !</li>
<li>The surprising negative effect of the max20MinPower is no more</li>
</ul>
<p>Notice though that the RMSE and the adjusted <span class="math inline">\(R^2\)</span> degraded… See the variable selection to see how to mitigate that problem.</p>
</div>
<div id="feature-engineering-and-functional-specification" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Feature engineering and functional specification</h3>
<p>The omitted variable bias makes it very important to include as much variables as possible if you want to be able to estimate the coefficient as accurately as possible. What you can do is add :</p>
<ul>
<li>Exponents to the regressors</li>
<li>Interactions between regressors</li>
</ul>
<p>Example with 2 variables <span class="math inline">\(y=b_1x_1 + b_2x_2 + b_3x_1^2 + b_4x_1x_2 + \epsilon\)</span></p>
<p>In this case : <span class="math inline">\(\dfrac{\partial y}{\partial x1} = b_1+2b_3x_1+b_4x_2\)</span></p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="reg.html#cb246-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span><span class="st"> </span>avgPower <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(avgPower<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span></span>
<span id="cb246-2"><a href="reg.html#cb246-2"></a><span class="st">             </span>distance <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(avgPower<span class="op">*</span>distance)<span class="op">+</span><span class="st">  </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower , <span class="dt">data=</span>dat_bike)</span>
<span id="cb246-3"><a href="reg.html#cb246-3"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + I(avgPower^2) + avgBikeCadence + 
##     distance + I(avgPower * distance) + avgHr + max20MinPower, 
##     data = dat_bike)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -33.917  -3.359  -0.905   2.912  21.795 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             1.357e+02  1.401e+01   9.686  &lt; 2e-16 ***
## avgPower               -1.091e-01  1.258e-01  -0.867 0.386163    
## I(avgPower^2)           8.780e-04  2.536e-04   3.462 0.000574 ***
## avgBikeCadence         -1.292e+00  7.750e-02 -16.675  &lt; 2e-16 ***
## distance                4.553e-01  8.268e-02   5.506 5.40e-08 ***
## I(avgPower * distance) -1.417e-03  3.253e-04  -4.356 1.55e-05 ***
## avgHr                  -5.727e-02  3.197e-02  -1.791 0.073726 .  
## max20MinPower          -6.822e-02  1.535e-02  -4.444 1.05e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.454 on 614 degrees of freedom
##   (1870 observations deleted due to missingness)
## Multiple R-squared:  0.8372,	Adjusted R-squared:  0.8354 
## F-statistic: 451.1 on 7 and 614 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="reg.html#cb248-1"></a>reg_full &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>(avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower <span class="op">+</span><span class="st"> </span>elevationGain)<span class="op">^</span><span class="dv">2</span>, <span class="dt">data=</span>dat_bike)</span>
<span id="cb248-2"><a href="reg.html#cb248-2"></a><span class="kw">summary</span>(reg_full)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ (avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain)^2, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.1520  -1.6039  -0.2125   1.1575  17.2608 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   1.275e+02  4.291e+01   2.971 0.003136 ** 
## avgPower                      2.369e+00  2.726e-01   8.691  &lt; 2e-16 ***
## avgBikeCadence               -8.207e-01  5.625e-01  -1.459 0.145275    
## distance                     -2.150e+00  2.698e-01  -7.971 1.40e-14 ***
## avgHr                        -1.461e+00  4.516e-01  -3.235 0.001311 ** 
## max20MinPower                -1.421e+00  2.394e-01  -5.935 6.02e-09 ***
## elevationGain                 4.233e-02  1.954e-02   2.167 0.030793 *  
## avgPower:avgBikeCadence      -3.128e-02  3.010e-03 -10.392  &lt; 2e-16 ***
## avgPower:distance            -2.345e-03  7.476e-04  -3.137 0.001821 ** 
## avgPower:avgHr                4.632e-03  1.614e-03   2.869 0.004313 ** 
## avgPower:max20MinPower        4.628e-04  2.141e-04   2.162 0.031177 *  
## avgPower:elevationGain       -2.371e-04  6.007e-05  -3.948 9.20e-05 ***
## avgBikeCadence:distance       3.529e-02  2.862e-03  12.331  &lt; 2e-16 ***
## avgBikeCadence:avgHr          1.174e-02  5.294e-03   2.217 0.027109 *  
## avgBikeCadence:max20MinPower  1.757e-02  2.456e-03   7.152 3.64e-12 ***
## avgBikeCadence:elevationGain -5.565e-04  1.794e-04  -3.102 0.002046 ** 
## distance:avgHr               -2.098e-03  1.182e-03  -1.775 0.076613 .  
## distance:max20MinPower       -1.296e-04  5.249e-04  -0.247 0.805185    
## distance:elevationGain        4.559e-06  1.288e-05   0.354 0.723472    
## avgHr:max20MinPower          -2.513e-03  1.417e-03  -1.773 0.076914 .  
## avgHr:elevationGain           1.972e-04  1.008e-04   1.957 0.050990 .  
## max20MinPower:elevationGain   1.276e-04  3.286e-05   3.883 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.707 on 435 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.9279,	Adjusted R-squared:  0.9244 
## F-statistic: 266.5 on 21 and 435 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="variable-selection" class="section level3">
<h3><span class="header-section-number">7.1.5</span> Variable selection</h3>
<p>So far we focused on getting the best coefficient estimates to be able to interpret how features impact our target variable (“explainable AI”), but following the previous logic, adding the more feature the better ! However, when focusing on the best prediction, you are more interested in finding the most general model which will perform well <em>out of sample</em> adding more and more variables can lead, as a matter of fact, to an overfitted model, which will hardly generalize.</p>
<p>This is illustration of the bias-variance trade-off which you will see more in depth during the machine learning session.</p>
<p><img src="img/Overfitting.png" />
Regarding regression, avoiding overfitting can be done with variable selection : starting from an extensive model, the procedure will try every feature combination that leads to the best prediction. There are 3 ways of constructing the models :</p>
<ul>
<li>backward selection : remove the less useful feature at a time</li>
<li>forward selection : introduce the most useful feature at a time</li>
<li>stepwise selection : a mixture of the previous methods</li>
</ul>
<p>The quality of each model is determined by the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC</a> or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC</a> which are a function of the opposite of the log-likelihood (because OLS can also be estimated with MLE) and the number of parameters. The lower this number, the better the model.</p>
<p>We can implement this method easily</p>
<div class="sourceCode" id="cb250"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb250-1"><a href="reg.html#cb250-1"></a>selection &lt;-<span class="st"> </span><span class="kw">step</span>(reg_full)</span></code></pre></div>
<pre><code>## Start:  AIC=1219.11
## avgSpeed ~ (avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain)^2
## 
##                                Df Sum of Sq    RSS    AIC
## - distance:max20MinPower        1      0.84 5980.1 1217.2
## - distance:elevationGain        1      1.72 5981.0 1217.2
## &lt;none&gt;                                      5979.2 1219.1
## - avgHr:max20MinPower           1     43.21 6022.5 1220.4
## - distance:avgHr                1     43.30 6022.5 1220.4
## - avgHr:elevationGain           1     52.64 6031.9 1221.1
## - avgPower:max20MinPower        1     64.24 6043.5 1222.0
## - avgBikeCadence:avgHr          1     67.59 6046.8 1222.2
## - avgPower:avgHr                1    113.17 6092.4 1225.7
## - avgBikeCadence:elevationGain  1    132.29 6111.5 1227.1
## - avgPower:distance             1    135.29 6114.5 1227.3
## - max20MinPower:elevationGain   1    207.20 6186.4 1232.7
## - avgPower:elevationGain        1    214.21 6193.5 1233.2
## - avgBikeCadence:max20MinPower  1    703.12 6682.4 1267.9
## - avgPower:avgBikeCadence       1   1484.41 7463.6 1318.5
## - avgBikeCadence:distance       1   2090.01 8069.3 1354.1
## 
## Step:  AIC=1217.18
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:max20MinPower + avgPower:elevationGain + 
##     avgBikeCadence:distance + avgBikeCadence:avgHr + avgBikeCadence:max20MinPower + 
##     avgBikeCadence:elevationGain + distance:avgHr + distance:elevationGain + 
##     avgHr:max20MinPower + avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq    RSS    AIC
## - distance:elevationGain        1      1.07 5981.1 1215.3
## &lt;none&gt;                                      5980.1 1217.2
## - distance:avgHr                1     42.48 6022.6 1218.4
## - avgHr:max20MinPower           1     46.57 6026.6 1218.7
## - avgHr:elevationGain           1     51.93 6032.0 1219.1
## - avgPower:max20MinPower        1     63.74 6043.8 1220.0
## - avgBikeCadence:avgHr          1     69.39 6049.5 1220.5
## - avgPower:avgHr                1    120.80 6100.9 1224.3
## - avgBikeCadence:elevationGain  1    196.06 6176.1 1229.9
## - avgPower:elevationGain        1    256.61 6236.7 1234.4
## - max20MinPower:elevationGain   1    356.88 6337.0 1241.7
## - avgPower:distance             1    392.97 6373.0 1244.3
## - avgBikeCadence:max20MinPower  1    763.84 6743.9 1270.1
## - avgPower:avgBikeCadence       1   1555.90 7536.0 1320.9
## - avgBikeCadence:distance       1   2289.03 8269.1 1363.3
## 
## Step:  AIC=1215.26
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:max20MinPower + avgPower:elevationGain + 
##     avgBikeCadence:distance + avgBikeCadence:avgHr + avgBikeCadence:max20MinPower + 
##     avgBikeCadence:elevationGain + distance:avgHr + avgHr:max20MinPower + 
##     avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq    RSS    AIC
## &lt;none&gt;                                      5981.1 1215.3
## - distance:avgHr                1     42.29 6023.4 1216.5
## - avgHr:max20MinPower           1     51.09 6032.2 1217.2
## - avgHr:elevationGain           1     60.15 6041.3 1217.8
## - avgBikeCadence:avgHr          1     69.05 6050.2 1218.5
## - avgPower:max20MinPower        1     69.57 6050.7 1218.5
## - avgPower:avgHr                1    123.62 6104.8 1222.6
## - avgBikeCadence:elevationGain  1    197.63 6178.8 1228.1
## - avgPower:elevationGain        1    326.10 6307.2 1237.5
## - avgPower:distance             1    398.40 6379.5 1242.7
## - max20MinPower:elevationGain   1    491.53 6472.7 1249.3
## - avgBikeCadence:max20MinPower  1   1102.37 7083.5 1290.6
## - avgPower:avgBikeCadence       1   1747.29 7728.4 1330.4
## - avgBikeCadence:distance       1   2673.93 8655.1 1382.1</code></pre>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="reg.html#cb252-1"></a><span class="kw">summary</span>(selection)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain + avgPower:avgBikeCadence + 
##     avgPower:distance + avgPower:avgHr + avgPower:max20MinPower + 
##     avgPower:elevationGain + avgBikeCadence:distance + avgBikeCadence:avgHr + 
##     avgBikeCadence:max20MinPower + avgBikeCadence:elevationGain + 
##     distance:avgHr + avgHr:max20MinPower + avgHr:elevationGain + 
##     max20MinPower:elevationGain, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.1360  -1.6132  -0.2158   1.1313  17.2782 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   1.299e+02  4.223e+01   3.077 0.002223 ** 
## avgPower                      2.396e+00  2.619e-01   9.149  &lt; 2e-16 ***
## avgBikeCadence               -8.535e-01  5.535e-01  -1.542 0.123771    
## distance                     -2.149e+00  2.393e-01  -8.981  &lt; 2e-16 ***
## avgHr                        -1.464e+00  4.466e-01  -3.278 0.001129 ** 
## max20MinPower                -1.455e+00  2.165e-01  -6.719 5.71e-11 ***
## elevationGain                 4.465e-02  1.713e-02   2.607 0.009441 ** 
## avgPower:avgBikeCadence      -3.167e-02  2.803e-03 -11.299  &lt; 2e-16 ***
## avgPower:distance            -2.467e-03  4.572e-04  -5.395 1.12e-07 ***
## avgPower:avgHr                4.742e-03  1.578e-03   3.005 0.002806 ** 
## avgPower:max20MinPower        4.643e-04  2.059e-04   2.255 0.024653 *  
## avgPower:elevationGain       -2.364e-04  4.844e-05  -4.881 1.48e-06 ***
## avgBikeCadence:distance       3.518e-02  2.517e-03  13.977  &lt; 2e-16 ***
## avgBikeCadence:avgHr          1.182e-02  5.263e-03   2.246 0.025194 *  
## avgBikeCadence:max20MinPower  1.807e-02  2.014e-03   8.975  &lt; 2e-16 ***
## avgBikeCadence:elevationGain -5.812e-04  1.530e-04  -3.800 0.000165 ***
## distance:avgHr               -2.057e-03  1.170e-03  -1.758 0.079484 .  
## avgHr:max20MinPower          -2.645e-03  1.369e-03  -1.932 0.053994 .  
## avgHr:elevationGain           2.026e-04  9.667e-05   2.096 0.036623 *  
## max20MinPower:elevationGain   1.253e-04  2.090e-05   5.993 4.32e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.7 on 437 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.9279,	Adjusted R-squared:  0.9247 
## F-statistic: 295.8 on 19 and 437 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="exercises" class="section level3">
<h3><span class="header-section-number">7.1.6</span> Exercises</h3>
<ul>
<li>From the last functional form used, design a graphic that shows the final impact of an increase in power to the average speed, taking the distance into account.</li>
<li>Design a regression model that will predict best the theoretical average speed for indoor bike activities (that have no speed, no coordinates…). Feature importance can be very important. Example : to prepare for competitions (that take place between may-september), I always follow a structured training plan at some point. This has a direct impact on the performances. Can you identify when this preparation starts and how to integrate it in the model ? This closely linked to your assignment ;)</li>
<li>Can you identify the measurement errors (thanks to residuals)</li>
</ul>
</div>
</div>
<div id="logitic-regression" class="section level2">
<h2><span class="header-section-number">7.2</span> Logitic regression</h2>
<div id="mathematical-formulation" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Mathematical formulation</h3>
<p>Logistic regression aims to model a <em>binary</em> output. In this case, <span class="math inline">\(y \in \{0,1\}\)</span> and the previous specification can’t apply. We still have a linear relationship, but which applies to the log-odd ratio :</p>
<p><span class="math display">\[log \dfrac{\mathbb{P}(y=1|x)}{1-\mathbb{P}(y=1|x)} = log \dfrac{^p}{1-p} = x_ib + \epsilon_i\]</span></p>
<p>This is called the <strong>link function</strong> and working the expression further we find that : <span class="math inline">\(p(x_i;b) = \mathbb{P}(y_i=1|x_i) = \dfrac{1}{1+e^{-x_ib}}\)</span></p>
<p>This allows us to derive the likelihood :</p>
<p><span class="math display">\[\mathcal{L}(b) = \prod_{i=1}^n p(x_i;b)^{y_i} \cdot (1-p(x_i;b))^{1-y_i}\]</span></p>
<p>This expression can be simplified, but there is no exact expression as for the OLS <span class="math inline">\(\rightarrow\)</span> the optimal solution has to be found via numerical optimization (eg Newton-Raphson).</p>
</div>
<div id="implementation-in-r-and-interpretation" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Implementation in R and interpretation</h3>
<p>In R, we use the <code>glm</code> function while specifying the family. We model the probability of an activity to be bike or something else, which is a binary variable.</p>
<div class="sourceCode" id="cb254"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb254-1"><a href="reg.html#cb254-1"></a>logit &lt;-<span class="st"> </span><span class="kw">glm</span>(is_bike<span class="op">~</span>distance<span class="op">+</span>duration<span class="op">+</span>elevationGain<span class="op">+</span>avgSpeed<span class="op">+</span>avgHr,<span class="dt">data=</span>dat_clean,<span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb254-2"><a href="reg.html#cb254-2"></a><span class="kw">summary</span>(logit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = is_bike ~ distance + duration + elevationGain + 
##     avgSpeed + avgHr, family = &quot;binomial&quot;, data = dat_clean)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.1893  -0.7940   0.1199   0.6260   3.7661  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)    8.451e+00  5.147e-01  16.419  &lt; 2e-16 ***
## distance       3.862e-02  7.815e-03   4.942 7.72e-07 ***
## duration       1.955e-03  2.946e-03   0.663   0.5071    
## elevationGain -9.304e-05  4.615e-05  -2.016   0.0438 *  
## avgSpeed       2.718e-02  1.080e-02   2.517   0.0118 *  
## avgHr         -6.839e-02  3.412e-03 -20.041  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 4439.8  on 3204  degrees of freedom
## Residual deviance: 2972.5  on 3199  degrees of freedom
##   (1920 observations deleted due to missingness)
## AIC: 2984.5
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The sign of the coefficient indicates whether the feature increases the probability for an activity to be a ride ride or not. However, the values cannot be interpreted as directly as in the case of the linear regression. But you can use the exponent of the value of the coefficient and interpret it in terms of odd-ratios.
For instance, adding one more kilometer to the average distance multiplies the probability for an activity to be a ride <em>rather than anything else</em> by 1.0393797, meaning 4% more chances. In the contrary, an activity that has 1 bpm more than the average HR has 6.6100901 6% less chances to be a ride. This makes sense because, as observed earlier, rides are longer and the heart rate is a bit smaller than for other activities.</p>
</div>
<div id="goodness-of-fit" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Goodness of fit</h3>
<p>As you might have noticed, there is no <span class="math inline">\(R^2\)</span> or RMSE in our case, just the AIC (which only allows you to compare different models, not know how good the model is). What we can do is check the fitted values of the model and the actual values</p>
<div class="sourceCode" id="cb256"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb256-1"><a href="reg.html#cb256-1"></a>pred &lt;-<span class="st"> </span><span class="kw">predict</span>(logit,dat_clean,<span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</span>
<span id="cb256-2"><a href="reg.html#cb256-2"></a>pred_bin &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(pred<span class="op">&gt;</span>.<span class="dv">5</span>)</span>
<span id="cb256-3"><a href="reg.html#cb256-3"></a><span class="kw">table</span>(pred_bin,dat_clean<span class="op">$</span>is_bike)</span></code></pre></div>
<pre><code>##         
## pred_bin FALSE TRUE
##        0  1418  413
##        1   133 1241</code></pre>
<p>And we can compute the accuracy as the sum of correct predictions divided by total number of activities : 0.8296412
You can derive other goodness of fit metrics from the previous <strong>confusion matrix</strong> :</p>
<ul>
<li>Sensitivity (recall) : <span class="math inline">\(\dfrac{TP}{TP+FN}\)</span></li>
<li>Specificity : <span class="math inline">\(\dfrac{TN}{TN+FP}\)</span></li>
<li>Precision : <span class="math inline">\(\dfrac{TP}{TP+FP}\)</span></li>
</ul>
<p><img src="img/conf_matrix.png" /></p>
<p>Depending on your business use case, you will focus more on one or the other metric. You will cover this in more detail durinng the machine learning week :)</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multivar.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DataExploration.pdf", "DataExploration.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
