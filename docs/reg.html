<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse</title>
  <meta name="description" content="Welcome to the wonderful world of data science and R !" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Welcome to the wonderful world of data science and R !" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Linear and logistic regression | Data exploration and statistics with R and the tidyverse" />
  
  <meta name="twitter:description" content="Welcome to the wonderful world of data science and R !" />
  

<meta name="author" content="Vivien Roussez (A1 Telekom Austria Group)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multivariate-analysis-and-dimension-reduction.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data exploration and statistics with R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Foreword</a></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#topics-of-the-week"><i class="fa fa-check"></i><b>2.1</b> Topics of the week</a></li>
<li class="chapter" data-level="2.2" data-path="intro.html"><a href="intro.html#the-data-science-workflow"><i class="fa fa-check"></i><b>2.2</b> The data science workflow</a></li>
<li class="chapter" data-level="2.3" data-path="intro.html"><a href="intro.html#resources"><i class="fa fa-check"></i><b>2.3</b> Resources</a></li>
<li class="chapter" data-level="2.4" data-path="intro.html"><a href="intro.html#data-of-the-week"><i class="fa fa-check"></i><b>2.4</b> Data of the week</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intro-r.html"><a href="intro-r.html"><i class="fa fa-check"></i><b>3</b> Introduction to R</a><ul>
<li class="chapter" data-level="3.1" data-path="intro-r.html"><a href="intro-r.html#what-is-r"><i class="fa fa-check"></i><b>3.1</b> What is R</a><ul>
<li class="chapter" data-level="3.1.1" data-path="intro-r.html"><a href="intro-r.html#description"><i class="fa fa-check"></i><b>3.1.1</b> Description</a></li>
<li class="chapter" data-level="3.1.2" data-path="intro-r.html"><a href="intro-r.html#objective-comparison-with-pyhton"><i class="fa fa-check"></i><b>3.1.2</b> (Objective) comparison with Pyhton</a></li>
<li class="chapter" data-level="3.1.3" data-path="intro-r.html"><a href="intro-r.html#what-can-i-do-with-r"><i class="fa fa-check"></i><b>3.1.3</b> What can I do with R</a></li>
<li class="chapter" data-level="3.1.4" data-path="intro-r.html"><a href="intro-r.html#quick-presentation-of-the-ecosystem"><i class="fa fa-check"></i><b>3.1.4</b> Quick presentation of the ecosystem</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="intro-r.html"><a href="intro-r.html#basic-commands-to-know"><i class="fa fa-check"></i><b>3.2</b> Basic commands to know</a></li>
<li class="chapter" data-level="3.3" data-path="intro-r.html"><a href="intro-r.html#data-structures-in-r"><i class="fa fa-check"></i><b>3.3</b> Data structures in R</a><ul>
<li class="chapter" data-level="3.3.1" data-path="intro-r.html"><a href="intro-r.html#basic-data-structures"><i class="fa fa-check"></i><b>3.3.1</b> Basic data structures</a></li>
<li class="chapter" data-level="3.3.2" data-path="intro-r.html"><a href="intro-r.html#explore-a-new-data-structure-or-object"><i class="fa fa-check"></i><b>3.3.2</b> Explore a new data structure (or object)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="manip.html"><a href="manip.html"><i class="fa fa-check"></i><b>4</b> Data manipulation</a><ul>
<li class="chapter" data-level="4.1" data-path="manip.html"><a href="manip.html#import"><i class="fa fa-check"></i><b>4.1</b> Import</a><ul>
<li class="chapter" data-level="4.1.1" data-path="manip.html"><a href="manip.html#text-files"><i class="fa fa-check"></i><b>4.1.1</b> Text files</a></li>
<li class="chapter" data-level="4.1.2" data-path="manip.html"><a href="manip.html#excel-files"><i class="fa fa-check"></i><b>4.1.2</b> Excel files</a></li>
<li class="chapter" data-level="4.1.3" data-path="manip.html"><a href="manip.html#more-formats"><i class="fa fa-check"></i><b>4.1.3</b> More formats</a></li>
<li class="chapter" data-level="4.1.4" data-path="manip.html"><a href="manip.html#read-from-databases-big-data"><i class="fa fa-check"></i><b>4.1.4</b> Read from databases / big data</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="manip.html"><a href="manip.html#the-grammar-of-data-manipulation"><i class="fa fa-check"></i><b>4.2</b> The grammar of data manipulation</a><ul>
<li class="chapter" data-level="4.2.1" data-path="manip.html"><a href="manip.html#the-pipe"><i class="fa fa-check"></i><b>4.2.1</b> The pipe</a></li>
<li class="chapter" data-level="4.2.2" data-path="manip.html"><a href="manip.html#the-verbs-of-manipulation"><i class="fa fa-check"></i><b>4.2.2</b> The verbs of manipulation</a></li>
<li class="chapter" data-level="4.2.3" data-path="manip.html"><a href="manip.html#filter-conditions"><i class="fa fa-check"></i><b>4.2.3</b> Filter : conditions</a></li>
<li class="chapter" data-level="4.2.4" data-path="manip.html"><a href="manip.html#mutate"><i class="fa fa-check"></i><b>4.2.4</b> Mutate</a></li>
<li class="chapter" data-level="4.2.5" data-path="manip.html"><a href="manip.html#summarize"><i class="fa fa-check"></i><b>4.2.5</b> Summarize</a></li>
<li class="chapter" data-level="4.2.6" data-path="manip.html"><a href="manip.html#manipulate-several-data-in-the-same-time"><i class="fa fa-check"></i><b>4.2.6</b> Manipulate several data in the same time</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="manip.html"><a href="manip.html#lets-import-and-wrangle-some-data"><i class="fa fa-check"></i><b>4.3</b> Let’s import and wrangle some data !</a><ul>
<li class="chapter" data-level="4.3.1" data-path="manip.html"><a href="manip.html#the-data"><i class="fa fa-check"></i><b>4.3.1</b> The data</a></li>
<li class="chapter" data-level="4.3.2" data-path="manip.html"><a href="manip.html#one-tool-you-will-need-lapply"><i class="fa fa-check"></i><b>4.3.2</b> One tool you will need : <code>lapply()</code></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="manip.html"><a href="manip.html#tidy-your-data"><i class="fa fa-check"></i><b>4.4</b> Tidy your data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="stats.html"><a href="stats.html"><i class="fa fa-check"></i><b>5</b> Statistics</a><ul>
<li class="chapter" data-level="5.1" data-path="stats.html"><a href="stats.html#definitions"><i class="fa fa-check"></i><b>5.1</b> Definitions</a><ul>
<li class="chapter" data-level="5.1.1" data-path="stats.html"><a href="stats.html#terminology"><i class="fa fa-check"></i><b>5.1.1</b> Terminology</a></li>
<li class="chapter" data-level="5.1.2" data-path="stats.html"><a href="stats.html#types-of-variables"><i class="fa fa-check"></i><b>5.1.2</b> Types of variables</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="stats.html"><a href="stats.html#univariate-statistics"><i class="fa fa-check"></i><b>5.2</b> Univariate statistics</a><ul>
<li class="chapter" data-level="5.2.1" data-path="stats.html"><a href="stats.html#numerical-variables"><i class="fa fa-check"></i><b>5.2.1</b> Numerical variables</a></li>
<li class="chapter" data-level="5.2.2" data-path="stats.html"><a href="stats.html#categorical-variables"><i class="fa fa-check"></i><b>5.2.2</b> Categorical variables</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="stats.html"><a href="stats.html#bivariate-statistics"><i class="fa fa-check"></i><b>5.3</b> Bivariate statistics</a><ul>
<li class="chapter" data-level="5.3.1" data-path="stats.html"><a href="stats.html#continuous-variables"><i class="fa fa-check"></i><b>5.3.1</b> 2 continuous variables</a></li>
<li class="chapter" data-level="5.3.2" data-path="stats.html"><a href="stats.html#categorical-variables-1"><i class="fa fa-check"></i><b>5.3.2</b> 2 categorical variables</a></li>
<li class="chapter" data-level="5.3.3" data-path="stats.html"><a href="stats.html#continuous-1-categorical-variable"><i class="fa fa-check"></i><b>5.3.3</b> 1 continuous, 1 categorical variable</a></li>
<li class="chapter" data-level="5.3.4" data-path="stats.html"><a href="stats.html#exercises-1"><i class="fa fa-check"></i><b>5.3.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="stats.html"><a href="stats.html#stat_inf"><i class="fa fa-check"></i><b>5.4</b> Statistical inference</a><ul>
<li class="chapter" data-level="5.4.1" data-path="stats.html"><a href="stats.html#the-statistical-model"><i class="fa fa-check"></i><b>5.4.1</b> The statistical model</a></li>
<li class="chapter" data-level="5.4.2" data-path="stats.html"><a href="stats.html#two-fundamental-theorems"><i class="fa fa-check"></i><b>5.4.2</b> Two fundamental theorems</a></li>
<li class="chapter" data-level="5.4.3" data-path="stats.html"><a href="stats.html#statistical-tests"><i class="fa fa-check"></i><b>5.4.3</b> Statistical tests</a></li>
<li class="chapter" data-level="5.4.4" data-path="stats.html"><a href="stats.html#other-estimators-maximum-of-likelihood"><i class="fa fa-check"></i><b>5.4.4</b> Other estimators : maximum of likelihood</a></li>
<li class="chapter" data-level="5.4.5" data-path="stats.html"><a href="stats.html#exercises-interprete-a-test-you-dont-know"><i class="fa fa-check"></i><b>5.4.5</b> Exercises : interprete a test you don’t know</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html"><i class="fa fa-check"></i><b>6</b> Multivariate analysis and dimension reduction</a><ul>
<li class="chapter" data-level="6.1" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#multivar"><i class="fa fa-check"></i><b>6.1</b> Multivariate analysis</a><ul>
<li class="chapter" data-level="6.1.1" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#adv_viz"><i class="fa fa-check"></i><b>6.1.1</b> Advanced visualization</a></li>
<li class="chapter" data-level="6.1.2" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#easily-explore-an-entire-dataset"><i class="fa fa-check"></i><b>6.1.2</b> Easily explore an entire dataset</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#multivariate-analysis-and-dimension-reduction-1"><i class="fa fa-check"></i><b>6.2</b> Multivariate analysis and dimension reduction</a><ul>
<li class="chapter" data-level="6.2.1" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#imputation"><i class="fa fa-check"></i><b>6.2.1</b> Imputation</a></li>
<li class="chapter" data-level="6.2.2" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#normalization"><i class="fa fa-check"></i><b>6.2.2</b> Normalization</a></li>
<li class="chapter" data-level="6.2.3" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#pca"><i class="fa fa-check"></i><b>6.2.3</b> PCA</a></li>
<li class="chapter" data-level="6.2.4" data-path="stats.html"><a href="stats.html#exercises"><i class="fa fa-check"></i><b>6.2.4</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#dimension-reduction"><i class="fa fa-check"></i><b>6.3</b> Dimension reduction</a><ul>
<li class="chapter" data-level="6.3.1" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#use-the-results-of-the-pca"><i class="fa fa-check"></i><b>6.3.1</b> Use the results of the PCA</a></li>
<li class="chapter" data-level="6.3.2" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#other-inertia-based-methods"><i class="fa fa-check"></i><b>6.3.2</b> Other inertia-based methods</a></li>
<li class="chapter" data-level="6.3.3" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#t-sne"><i class="fa fa-check"></i><b>6.3.3</b> t-SNE</a></li>
<li class="chapter" data-level="6.3.4" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#a-word-about-clustering"><i class="fa fa-check"></i><b>6.3.4</b> A word about clustering</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#visualization-bonus-dashboards-and-reports"><i class="fa fa-check"></i><b>6.4</b> Visualization bonus : dashboards and reports</a><ul>
<li class="chapter" data-level="6.4.1" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#shiny-and-rmarkdown"><i class="fa fa-check"></i><b>6.4.1</b> Shiny and rmarkdown</a></li>
<li class="chapter" data-level="6.4.2" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#web-based-graphics-with-plotly"><i class="fa fa-check"></i><b>6.4.2</b> Web-based graphics with <code>plotly</code></a></li>
<li class="chapter" data-level="6.4.3" data-path="multivariate-analysis-and-dimension-reduction.html"><a href="multivariate-analysis-and-dimension-reduction.html#other-packages-widgets"><i class="fa fa-check"></i><b>6.4.3</b> Other packages &amp; widgets</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="reg.html"><a href="reg.html"><i class="fa fa-check"></i><b>7</b> Linear and logistic regression</a><ul>
<li class="chapter" data-level="7.1" data-path="reg.html"><a href="reg.html#linear-regression"><i class="fa fa-check"></i><b>7.1</b> Linear regression</a><ul>
<li class="chapter" data-level="7.1.1" data-path="reg.html"><a href="reg.html#general-presentation"><i class="fa fa-check"></i><b>7.1.1</b> General presentation</a></li>
<li class="chapter" data-level="7.1.2" data-path="reg.html"><a href="reg.html#coefficients-interpretation-and-inference"><i class="fa fa-check"></i><b>7.1.2</b> Coefficients interpretation and inference</a></li>
<li class="chapter" data-level="7.1.3" data-path="reg.html"><a href="reg.html#the-frischwaugh-theorem-and-the-omitted-variable-bias"><i class="fa fa-check"></i><b>7.1.3</b> The Frisch–Waugh Theorem and the omitted variable bias</a></li>
<li class="chapter" data-level="7.1.4" data-path="reg.html"><a href="reg.html#feature-engineering-and-functional-specification"><i class="fa fa-check"></i><b>7.1.4</b> Feature engineering and functional specification</a></li>
<li class="chapter" data-level="7.1.5" data-path="reg.html"><a href="reg.html#variable-selection"><i class="fa fa-check"></i><b>7.1.5</b> Variable selection</a></li>
<li class="chapter" data-level="7.1.6" data-path="stats.html"><a href="stats.html#exercises"><i class="fa fa-check"></i><b>7.1.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="reg.html"><a href="reg.html#logitic-regression"><i class="fa fa-check"></i><b>7.2</b> Logitic regression</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data exploration and statistics with R and the tidyverse</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reg" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Linear and logistic regression</h1>
<p>Regression is the first machine learning algorithm. It allows you to model a <em>target variable</em> <span class="math inline">\(y\)</span> depending on a set of <em>explanatory variables</em> or <em>features</em> <span class="math inline">\(X\)</span> such that <span class="math inline">\(y=f(X) + \epsilon\)</span> where <span class="math inline">\(f\)</span> is a linear function (for linear regression).</p>
<div id="linear-regression" class="section level2">
<h2><span class="header-section-number">7.1</span> Linear regression</h2>
<p>We will jump directly to the <em>multiple regression model</em>, which is the generalization of the simple linear model, which you can check <a href="https://www.econometrics-with-r.org/4-lrwor.html">here</a></p>
<div id="general-presentation" class="section level3">
<h3><span class="header-section-number">7.1.1</span> General presentation</h3>
<p>The basic equation of the linear regression is
<span class="math display">\[ y_i = x_i \cdot b + \epsilon_i \Leftrightarrow y_i = \sum_{j=1}^p x_{ij} b_j + \epsilon_i\]</span></p>
<p>Where :</p>
<ul>
<li><span class="math inline">\(x_i\)</span> is a row-vector of size p (number of explanatory variables), containng the values of each feature of observation i. It is the row i of the matrix <span class="math inline">\(X = (x_{ij})\)</span></li>
<li>b is a column-vector of coefficients, one per explanatory variable</li>
<li><span class="math inline">\(\epsilon_i\)</span> is the error term for observation i</li>
</ul>
<p>This regression is said to be linear because it is <em>linear in the parameters</em>, you can however transform the original variables at will with non-linear functions (see feature engineering).</p>
<p>The biggest assumptions of this model are :</p>
<ul>
<li>Observations are iid</li>
<li>There is no perfect multi-collinearity among features</li>
<li><span class="math inline">\(\epsilon_i\)</span> has a zero conditional mean <span class="math inline">\(\mathbb{E}(\epsilon | X)=0\)</span></li>
</ul>
<p>This last condition helps us to derive an estimator for b (which can be derived in several ways) which is called the OLS estimator (Ordinary Least Squares), which is the solution of the optimization program :</p>
<p><span class="math display">\[\hat{b}=argmin_b \sum_{i=1}^n \epsilon_i^2 = argmin_b \sum_{i=1}^n (x_i-x_i \cdot b)^2\]</span></p>
<p>The solution is <span class="math inline">\(\hat{b} = (X&#39;X)^{-1}X&#39;y\)</span> where <span class="math inline">\(X&#39;=t(X)\)</span>. <span class="math inline">\((X&#39;X)^{-1}X\)</span> is the projection matrix over the hyperplane defined by the features.</p>
<p><img src="img/ols-regression-geometry.png" />
### Implementation and diagnostics</p>
<p>To implement a linear regression with R, we use the lm function :</p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="reg.html#cb246-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower, <span class="dt">data=</span>dat_bike)</span>
<span id="cb246-2"><a href="reg.html#cb246-2"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.81833 -0.09966 -0.02924  0.08703  0.63106 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.037e+00  1.859e-01  16.334  &lt; 2e-16 ***
## avgPower        7.041e-03  6.270e-04  11.231  &lt; 2e-16 ***
## avgBikeCadence -3.926e-02  2.052e-03 -19.131  &lt; 2e-16 ***
## distance        2.649e-08  3.346e-09   7.917 1.14e-14 ***
## avgHr          -1.268e-03  8.997e-04  -1.410    0.159    
## max20MinPower  -1.879e-03  4.231e-04  -4.441 1.06e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1824 on 616 degrees of freedom
##   (1870 observations deleted due to missingness)
## Multiple R-squared:  0.8309,	Adjusted R-squared:  0.8296 
## F-statistic: 605.6 on 5 and 616 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The goodness of fit is measured through 2 main statistics :</p>
<ul>
<li>Adjusted R-squared, <span class="math inline">\(1- \dfrac{n-1}{n-k-1} \dfrac{SSR}{TSS} \in [0,1]\)</span>, which takes the number of regressors into account. The closer to 1, the better the fit</li>
<li>RMSE (root mean squared error), or residual standard error which has to be compared to the average value of <span class="math inline">\(y\)</span>. the smaller the value, the better the fit.</li>
</ul>
</div>
<div id="coefficients-interpretation-and-inference" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Coefficients interpretation and inference</h3>
<p>Back to original equation, we can understand how much each feature influences in average the output.</p>
<p><span class="math display">\[ \dfrac{\partial y}{\partial x_1} = b_1\]</span>
Meaning that the increase of <span class="math inline">\(x_1\)</span> by one unit causes the output to increase in average by <span class="math inline">\(b_1\)</span> (which can of course be negative). In our example, one additional watt will result in an increase of the average speed by 0.007 100m/min</p>
<p>The fundamental hypothesis being fulfilled and the sample being large enough, the distribution of the OLS estimate <span class="math inline">\((b_1,...,b_p)\)</span> are jointly normally distributed, meaning that each <span class="math inline">\(\hat{b_j} \hookrightarrow \mathcal{N}(b_j,\sigma_{b_j}^2)\)</span>
We can therefore perform statistical tests following the previous methodology (see @ref(stat_inf).</p>
<p>The most common test is the Student test which tests the null hypothesis <span class="math inline">\(b_i=0\)</span>. This allows to check whether a regressor has a significant effect on the target variable or not.</p>
<p>But you have to check your residuals !</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="reg.html#cb248-1"></a><span class="kw">residuals</span>(reg) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb248-2"><a href="reg.html#cb248-2"></a><span class="st">  </span><span class="kw">data.frame</span>(<span class="dt">res=</span>.) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb248-3"><a href="reg.html#cb248-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(res)) <span class="op">+</span><span class="st"> </span><span class="kw">geom_density</span>() <span class="op">+</span><span class="st"> </span><span class="kw">theme_minimal</span>()</span></code></pre></div>
<p><img src="DataExploration_files/figure-html/unnamed-chunk-91-1.png" width="672" />
Those are pretty long tailed, which might reflect some outliers or a wrong functional specification !</p>
</div>
<div id="the-frischwaugh-theorem-and-the-omitted-variable-bias" class="section level3">
<h3><span class="header-section-number">7.1.3</span> The Frisch–Waugh Theorem and the omitted variable bias</h3>
<p>The <a href="https://en.wikipedia.org/wiki/Frisch%E2%80%93Waugh%E2%80%93Lovell_theorem">Frisch-Waugh theorem</a> tells us that adding a variable as regressor ensures that our estimates controls for the effect of this variable. In other words, you can interpret the coefficients’ values <em>ceteris paribus</em> (other things equal).</p>
<p>This also means that if you omit a variable, the coefficient of the other variables are likely to be biased, because you did not take an important variable into account. Back to our example, we can add the elevationGain variable and check what happens :</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="reg.html#cb249-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower <span class="op">+</span><span class="st"> </span>elevationGain, <span class="dt">data=</span>dat_bike)</span>
<span id="cb249-2"><a href="reg.html#cb249-2"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.48945 -0.10744 -0.01473  0.07470  0.54393 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     3.513e+00  1.842e-01  19.076  &lt; 2e-16 ***
## avgPower        3.817e-03  6.540e-04   5.837 1.02e-08 ***
## avgBikeCadence -4.226e-02  2.086e-03 -20.253  &lt; 2e-16 ***
## distance        5.518e-08  3.974e-09  13.884  &lt; 2e-16 ***
## avgHr           2.202e-04  8.746e-04   0.252    0.801    
## max20MinPower  -2.046e-04  4.297e-04  -0.476    0.634    
## elevationGain  -3.559e-06  2.651e-07 -13.424  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1649 on 450 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.8086,	Adjusted R-squared:  0.8061 
## F-statistic: 316.9 on 6 and 450 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>See how the coefficients changed. This is understandable because when climbing mountains :</p>
<ul>
<li>More power will not increase the speed, just maintain it (… or not)</li>
<li>The cadence is harder to maintain unless you have unlimited gears !</li>
<li>The surprising negative effect of the max20MinPower is no more</li>
</ul>
<p>Notice though that the RMSE and the adjusted <span class="math inline">\(R^2\)</span> degraded… See the variable selection to see how to mitigate that problem.</p>
</div>
<div id="feature-engineering-and-functional-specification" class="section level3">
<h3><span class="header-section-number">7.1.4</span> Feature engineering and functional specification</h3>
<p>The omitted variable bias makes it very important to include as much variables as possible if you want to be able to estimate the coefficient as accurately as possible. What you can do is add :</p>
<ul>
<li>Exponents to the regressors</li>
<li>Interactions between regressors</li>
</ul>
<p>Example with 2 variables <span class="math inline">\(y=b_1x_1 + b_2x_2 + b_3x_1^2 + b_4x_1x_2 + \epsilon\)</span></p>
<p>In this case : <span class="math inline">\(\dfrac{\partial y}{\partial x1} = b_1+2b_3x_1+b_4x_2\)</span></p>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="reg.html#cb251-1"></a>reg &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span><span class="st"> </span>avgPower <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(avgPower<span class="op">^</span><span class="dv">2</span>) <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span></span>
<span id="cb251-2"><a href="reg.html#cb251-2"></a><span class="st">             </span>distance <span class="op">+</span><span class="st"> </span><span class="kw">I</span>(avgPower<span class="op">*</span>distance)<span class="op">+</span><span class="st">  </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower , <span class="dt">data=</span>dat_bike)</span>
<span id="cb251-3"><a href="reg.html#cb251-3"></a><span class="kw">summary</span>(reg)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + I(avgPower^2) + avgBikeCadence + 
##     distance + I(avgPower * distance) + avgHr + max20MinPower, 
##     data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.94213 -0.09331 -0.02513  0.08090  0.60542 
## 
## Coefficients:
##                          Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)             3.770e+00  3.892e-01   9.686  &lt; 2e-16 ***
## avgPower               -3.031e-03  3.495e-03  -0.867 0.386163    
## I(avgPower^2)           2.439e-05  7.045e-06   3.462 0.000574 ***
## avgBikeCadence         -3.590e-02  2.153e-03 -16.675  &lt; 2e-16 ***
## distance                1.265e-07  2.297e-08   5.506 5.40e-08 ***
## I(avgPower * distance) -3.936e-10  9.036e-11  -4.356 1.55e-05 ***
## avgHr                  -1.591e-03  8.881e-04  -1.791 0.073726 .  
## max20MinPower          -1.895e-03  4.264e-04  -4.444 1.05e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1793 on 614 degrees of freedom
##   (1870 observations deleted due to missingness)
## Multiple R-squared:  0.8372,	Adjusted R-squared:  0.8354 
## F-statistic: 451.1 on 7 and 614 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="reg.html#cb253-1"></a>reg_full &lt;-<span class="st"> </span><span class="kw">lm</span>(avgSpeed<span class="op">~</span>(avgPower <span class="op">+</span><span class="st"> </span>avgBikeCadence <span class="op">+</span><span class="st"> </span>distance <span class="op">+</span><span class="st"> </span>avgHr <span class="op">+</span><span class="st"> </span>max20MinPower <span class="op">+</span><span class="st"> </span>elevationGain)<span class="op">^</span><span class="dv">2</span>, <span class="dt">data=</span>dat_bike)</span>
<span id="cb253-2"><a href="reg.html#cb253-2"></a><span class="kw">summary</span>(reg_full)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ (avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain)^2, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.44867 -0.04455 -0.00590  0.03215  0.47947 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   3.541e+00  1.192e+00   2.971 0.003136 ** 
## avgPower                      6.582e-02  7.573e-03   8.691  &lt; 2e-16 ***
## avgBikeCadence               -2.280e-02  1.562e-02  -1.459 0.145275    
## distance                     -5.973e-07  7.494e-08  -7.971 1.40e-14 ***
## avgHr                        -4.058e-02  1.255e-02  -3.235 0.001311 ** 
## max20MinPower                -3.946e-02  6.650e-03  -5.935 6.02e-09 ***
## elevationGain                 1.176e-05  5.427e-06   2.167 0.030793 *  
## avgPower:avgBikeCadence      -8.688e-04  8.361e-05 -10.392  &lt; 2e-16 ***
## avgPower:distance            -6.515e-10  2.077e-10  -3.137 0.001821 ** 
## avgPower:avgHr                1.287e-04  4.484e-05   2.869 0.004313 ** 
## avgPower:max20MinPower        1.286e-05  5.947e-06   2.162 0.031177 *  
## avgPower:elevationGain       -6.587e-08  1.669e-08  -3.948 9.20e-05 ***
## avgBikeCadence:distance       9.802e-09  7.949e-10  12.331  &lt; 2e-16 ***
## avgBikeCadence:avgHr          3.261e-04  1.471e-04   2.217 0.027109 *  
## avgBikeCadence:max20MinPower  4.880e-04  6.823e-05   7.152 3.64e-12 ***
## avgBikeCadence:elevationGain -1.546e-07  4.983e-08  -3.102 0.002046 ** 
## distance:avgHr               -5.827e-10  3.283e-10  -1.775 0.076613 .  
## distance:max20MinPower       -3.599e-11  1.458e-10  -0.247 0.805185    
## distance:elevationGain        1.266e-14  3.577e-14   0.354 0.723472    
## avgHr:max20MinPower          -6.980e-05  3.937e-05  -1.773 0.076914 .  
## avgHr:elevationGain           5.477e-08  2.799e-08   1.957 0.050990 .  
## max20MinPower:elevationGain   3.544e-08  9.127e-09   3.883 0.000119 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.103 on 435 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.9279,	Adjusted R-squared:  0.9244 
## F-statistic: 266.5 on 21 and 435 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="variable-selection" class="section level3">
<h3><span class="header-section-number">7.1.5</span> Variable selection</h3>
<p>So far we focused on getting the best coefficient estimates to be able to interpret how features impact our target variable (“explainable AI”), but following the previous logic, adding the more feature the better ! However, when focusing on the best prediction, you are more interested in finding the most general model which will perform well <em>out of sample</em> adding more and more variables can lead, as a matter of fact, to an overfitted model, which will hardly generalize.</p>
<p>This is illustration of the bias-variance trade-off which you will see more in depth during the machine learning session.</p>
<p><img src="img/Overfitting.svg" />
Regarding regression, avoiding overfitting can be done with variable selection : starting from an extensive model, the procedure will try every feature combination that leads to the best prediction. There are 3 ways of constructing the models :</p>
<ul>
<li>backward selection : remove the less useful feature at a time</li>
<li>forward selection : introduce the most useful feature at a time</li>
<li>stepwise selection : a mixture of the previous methods</li>
</ul>
<p>The quality of each model is determined by the <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">AIC</a> or <a href="https://en.wikipedia.org/wiki/Bayesian_information_criterion">BIC</a> which are a function of the opposite of the log-likelihood (because OLS can also be estimated with MLE) and the number of parameters. The lower this number, the better the model.</p>
<p>We can implement this method easily</p>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="reg.html#cb255-1"></a>selection &lt;-<span class="st"> </span><span class="kw">step</span>(reg_full)</span></code></pre></div>
<pre><code>## Start:  AIC=-2056.22
## avgSpeed ~ (avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain)^2
## 
##                                Df Sum of Sq    RSS     AIC
## - distance:max20MinPower        1   0.00065 4.6143 -2058.2
## - distance:elevationGain        1   0.00133 4.6149 -2058.1
## &lt;none&gt;                                      4.6136 -2056.2
## - avgHr:max20MinPower           1   0.03334 4.6470 -2054.9
## - distance:avgHr                1   0.03341 4.6470 -2054.9
## - avgHr:elevationGain           1   0.04062 4.6542 -2054.2
## - avgPower:max20MinPower        1   0.04957 4.6632 -2053.3
## - avgBikeCadence:avgHr          1   0.05215 4.6658 -2053.1
## - avgPower:avgHr                1   0.08732 4.7009 -2049.7
## - avgBikeCadence:elevationGain  1   0.10207 4.7157 -2048.2
## - avgPower:distance             1   0.10439 4.7180 -2048.0
## - max20MinPower:elevationGain   1   0.15988 4.7735 -2042.7
## - avgPower:elevationGain        1   0.16529 4.7789 -2042.1
## - avgBikeCadence:max20MinPower  1   0.54253 5.1561 -2007.4
## - avgPower:avgBikeCadence       1   1.14538 5.7590 -1956.9
## - avgBikeCadence:distance       1   1.61266 6.2263 -1921.2
## 
## Step:  AIC=-2058.16
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:max20MinPower + avgPower:elevationGain + 
##     avgBikeCadence:distance + avgBikeCadence:avgHr + avgBikeCadence:max20MinPower + 
##     avgBikeCadence:elevationGain + distance:avgHr + distance:elevationGain + 
##     avgHr:max20MinPower + avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq    RSS     AIC
## - distance:elevationGain        1   0.00082 4.6151 -2060.1
## &lt;none&gt;                                      4.6143 -2058.2
## - distance:avgHr                1   0.03278 4.6470 -2056.9
## - avgHr:max20MinPower           1   0.03593 4.6502 -2056.6
## - avgHr:elevationGain           1   0.04007 4.6543 -2056.2
## - avgPower:max20MinPower        1   0.04919 4.6634 -2055.3
## - avgBikeCadence:avgHr          1   0.05354 4.6678 -2054.9
## - avgPower:avgHr                1   0.09321 4.7075 -2051.0
## - avgBikeCadence:elevationGain  1   0.15128 4.7655 -2045.4
## - avgPower:elevationGain        1   0.19800 4.8123 -2041.0
## - max20MinPower:elevationGain   1   0.27537 4.8896 -2033.7
## - avgPower:distance             1   0.30322 4.9175 -2031.1
## - avgBikeCadence:max20MinPower  1   0.58938 5.2036 -2005.2
## - avgPower:avgBikeCadence       1   1.20054 5.8148 -1954.5
## - avgBikeCadence:distance       1   1.76623 6.3805 -1912.0
## 
## Step:  AIC=-2060.08
## avgSpeed ~ avgPower + avgBikeCadence + distance + avgHr + max20MinPower + 
##     elevationGain + avgPower:avgBikeCadence + avgPower:distance + 
##     avgPower:avgHr + avgPower:max20MinPower + avgPower:elevationGain + 
##     avgBikeCadence:distance + avgBikeCadence:avgHr + avgBikeCadence:max20MinPower + 
##     avgBikeCadence:elevationGain + distance:avgHr + avgHr:max20MinPower + 
##     avgHr:elevationGain + max20MinPower:elevationGain
## 
##                                Df Sum of Sq    RSS     AIC
## &lt;none&gt;                                      4.6151 -2060.1
## - distance:avgHr                1   0.03263 4.6477 -2058.9
## - avgHr:max20MinPower           1   0.03942 4.6545 -2058.2
## - avgHr:elevationGain           1   0.04641 4.6615 -2057.5
## - avgBikeCadence:avgHr          1   0.05328 4.6684 -2056.8
## - avgPower:max20MinPower        1   0.05368 4.6688 -2056.8
## - avgPower:avgHr                1   0.09538 4.7105 -2052.7
## - avgBikeCadence:elevationGain  1   0.15249 4.7676 -2047.2
## - avgPower:elevationGain        1   0.25162 4.8667 -2037.8
## - avgPower:distance             1   0.30741 4.9225 -2032.6
## - max20MinPower:elevationGain   1   0.37927 4.9943 -2026.0
## - avgBikeCadence:max20MinPower  1   0.85059 5.4657 -1984.8
## - avgPower:avgBikeCadence       1   1.34822 5.9633 -1945.0
## - avgBikeCadence:distance       1   2.06322 6.6783 -1893.2</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="reg.html#cb257-1"></a><span class="kw">summary</span>(selection)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = avgSpeed ~ avgPower + avgBikeCadence + distance + 
##     avgHr + max20MinPower + elevationGain + avgPower:avgBikeCadence + 
##     avgPower:distance + avgPower:avgHr + avgPower:max20MinPower + 
##     avgPower:elevationGain + avgBikeCadence:distance + avgBikeCadence:avgHr + 
##     avgBikeCadence:max20MinPower + avgBikeCadence:elevationGain + 
##     distance:avgHr + avgHr:max20MinPower + avgHr:elevationGain + 
##     max20MinPower:elevationGain, data = dat_bike)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.44822 -0.04481 -0.00599  0.03142  0.47995 
## 
## Coefficients:
##                                Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                   3.610e+00  1.173e+00   3.077 0.002223 ** 
## avgPower                      6.657e-02  7.276e-03   9.149  &lt; 2e-16 ***
## avgBikeCadence               -2.371e-02  1.537e-02  -1.542 0.123771    
## distance                     -5.971e-07  6.648e-08  -8.981  &lt; 2e-16 ***
## avgHr                        -4.067e-02  1.241e-02  -3.278 0.001129 ** 
## max20MinPower                -4.042e-02  6.015e-03  -6.719 5.71e-11 ***
## elevationGain                 1.240e-05  4.757e-06   2.607 0.009441 ** 
## avgPower:avgBikeCadence      -8.798e-04  7.787e-05 -11.299  &lt; 2e-16 ***
## avgPower:distance            -6.852e-10  1.270e-10  -5.395 1.12e-07 ***
## avgPower:avgHr                1.317e-04  4.383e-05   3.005 0.002806 ** 
## avgPower:max20MinPower        1.290e-05  5.721e-06   2.255 0.024653 *  
## avgPower:elevationGain       -6.568e-08  1.346e-08  -4.881 1.48e-06 ***
## avgBikeCadence:distance       9.771e-09  6.991e-10  13.977  &lt; 2e-16 ***
## avgBikeCadence:avgHr          3.283e-04  1.462e-04   2.246 0.025194 *  
## avgBikeCadence:max20MinPower  5.020e-04  5.593e-05   8.975  &lt; 2e-16 ***
## avgBikeCadence:elevationGain -1.615e-07  4.249e-08  -3.800 0.000165 ***
## distance:avgHr               -5.714e-10  3.251e-10  -1.758 0.079484 .  
## avgHr:max20MinPower          -7.348e-05  3.803e-05  -1.932 0.053994 .  
## avgHr:elevationGain           5.629e-08  2.685e-08   2.096 0.036623 *  
## max20MinPower:elevationGain   3.479e-08  5.806e-09   5.993 4.32e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1028 on 437 degrees of freedom
##   (2035 observations deleted due to missingness)
## Multiple R-squared:  0.9279,	Adjusted R-squared:  0.9247 
## F-statistic: 295.8 on 19 and 437 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
<div id="exercises" class="section level3">
<h3><span class="header-section-number">7.1.6</span> Exercises</h3>
<ul>
<li>From the last functional form used, design a graphic that shows the final impact of an increase in power to the average speed, taking the distance into account.</li>
<li>Design a regression model that will predict best the theoretical average speed for indoor bike activities (that have no speed, no coordinates…)</li>
</ul>
</div>
</div>
<div id="logitic-regression" class="section level2">
<h2><span class="header-section-number">7.2</span> Logitic regression</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multivariate-analysis-and-dimension-reduction.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["DataExploration.pdf", "DataExploration.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
